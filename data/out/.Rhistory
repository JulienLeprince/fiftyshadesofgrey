install.packages(c("doParallel", "foreach"))
library(cstmr)
library(stringr)
install.packages("ctsmr", repos = c(ctsmr = "http://ctsm.info/repo/dev", getOption("repos")))
library(cstmr)
library(cstmr)
write('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', file = "~/.Renviron", append = TRUE)
library(cstmr)
library(stringr)
library(lubridate)
library(scales)
# Define paths
root_directory = "C:/Users/20190285/Documents/GitHub/fiftyshadesofgrey"
path_out = paste(root_directory, "/data/out/", sep="")
path_in = paste(root_directory, "/data/in/", sep="")
# Set the working directory. Change this to the location of the example on the computer. Note that "/" is always used in R, also in Windows
setwd(paste(root_directory, "/src", sep=""))
# Source the scripts with functions in the "src" folder. Just a neat way of arranging helping functions in R
source("allmodels.R")
source("utils.R")
# Get all input files names
setwd(path_out)
list_file_names <- list.files(pattern = "*_fit.rda")
## ------------------------------------------------- Model selection post-processing -------------------------------------------------
# Saving dataframe initialization
R_coefs = c('Ria', 'Rie', 'Rea', 'Rih', 'Rim', 'Ris')
# Saving dataframe initialization
col_names <- c("uuid", "model_name", "HTC", "nCPBES", "iteration", "significance_prop", "residual_std", "residual_mean",
"Ti0" , "Tm0" , "Te0" , "Th0" , "Ts0" ,
"Ci" , "Cm" , "Ce" , "Ch" , "Cs" , "Rie", "Rea", "Ria", "Rim", "Rih", "Ris", "Rh" ,
"Aw" , "Ae" ,
"p11", "p22", "p33", "p44", "p55", "e11",
"Ti0_p" , "Tm0_p" , "Te0_p" , "Th0_p" , "Ts0_p" , "Ci_p" , "Cm_p" , "Ce_p" , "Ch_p" , "Cs_p" ,
"Rie_p", "Rea_p", "Ria_p", "Rim_p", "Rih_p", "Ris_p", "Rh_p" ,
"Aw_p" , "Ae_p" ,
"p11_p", "p22_p", "p33_p", "p44_p", "p55_p", "e11_p")
col_names2 <- c("uuid", "ite1", "ite2", "ite3", "ite4", "ite5", "ite6")
# Initialize dataframes
# Results
df_res <- data.frame(matrix(ncol = length(col_names), nrow = 0))
colnames(df_res) <- col_names
# Best path
df_paths <- data.frame(matrix(ncol = length(col_names2), nrow = 0))
colnames(df_paths) <- col_names2
# Best nCPBES
df_nCPBES <- data.frame(matrix(ncol = length(col_names2), nrow = 0))
colnames(df_nCPBES) <- col_names2
# Estimated coefficient p-values, for significance evaluation
coef_pvals <- c("Ti0_p" , "Tm0_p" , "Te0_p" , "Th0_p" , "Ts0_p" ,
"Ci_p" , "Cm_p" , "Ce_p" , "Ch_p" , "Cs_p" ,
"Rie_p", "Rea_p", "Ria_p", "Rim_p", "Rih_p", "Ris_p", "Rh_p" ,
"Aw_p" , "Ae_p" ,
"p11_p", "p22_p", "p33_p", "p44_p", "p55_p", "e11_p")
### Looping over building model files
counts <- 0
list_badoutputs <- c()
for (file in list_file_names){
# --- PREPROCESSING ---
# Read the csv file
load(file)
# Get blg uuid from file name
split_file_name <- str_split_fixed(file, "_", 3)
uuid_filtering <- sapply(split_file_name, tail, 1)[[1]]
# Testing if the result evaluated is correct
if (length(best_fit) == 1) {
list_badoutputs <- c(list_badoutputs, file)
next
} else {
counts <- counts + 1
}
# Extracting model result
val <- summary(best_fit)
# Identifying R coefs from results
coefs <- val$coefficients[1:(length(val$coefficients)/4),1]
coefs_p <- val$coefficients[1:(length(val$coefficients)/4),4]
R_coefs_considered <- Reduce(intersect,list(R_coefs,names(coefs)))
# Calculating HTC in function of available R coefficients
if ("Ria" %in% R_coefs_considered & "Rie" %in% R_coefs_considered & "Rea" %in% R_coefs_considered){
HTC <- 1/(coefs[['Rie']] + coefs[['Rea']]) + 1/coefs[['Ria']] # [kW/C]
} else if ("Rie" %in% R_coefs_considered & "Rea" %in% R_coefs_considered) {
HTC <- 1/(coefs[['Rie']] + coefs[['Rea']]) # [kW/C]
} else {
HTC <- 1/coefs[['Ria']] # [kW/C]
}
# Saving HTC value
df_res[[counts, 3]] <- HTC
# Save coefficients and their respective p-values
for (i in 1:length(names(coefs))){
df_res[[counts,  names(coefs)[i]]] <- coefs[[names(coefs)[i]]]        # parameter estimates
df_res[[counts,  paste(names(coefs_p)[i], "_p", sep="")]] <- coefs_p[[names(coefs_p)[i]]]  # parameter p-values
}
# Save uuid, model name
df_res[[counts, 1]] <- uuid_filtering
df_res[[counts, 2]] <- best_fit$model_name
# Save model selection path
df_paths[[counts, 1]] <- uuid_filtering
for (i in 1:length(best_fit$best_path)){
df_paths[[counts, i+1]] <- best_fit$best_path[i]
}
# Save model nCPBES
df_nCPBES[[counts, 1]] <- uuid_filtering
for (i in 1:length(best_fit$nCPBES)){
df_nCPBES[[counts, i+1]] <- best_fit$nCPBES[i]
}
### Save normalized Cumulated Periodogram Boundary Excess Sum
df_res[[counts, 4]] <- tail(best_fit$nCPBES, n=1)
# Saving Model Iteration
df_res[[counts, 5]] <- length(best_fit$best_path)
# Significance of estimated parameter - proportion: significance_prop
signifiance <- c()
for (c in coef_pvals){
signifiance <- c(signifiance, df_res[[counts, c]] < 0.05)
}
significance_prop <- sum(signifiance[!is.na(signifiance)]*1)/length(signifiance[!is.na(signifiance)])*100
df_res[[counts, 6]] <- significance_prop
# Saving Residual standard deviation & Mean
df_res[[counts, 7]] <- sd(ts)
df_res[[counts, 8]] <- mean(ts)
}
# Save dataframe as csv file/ spark table
write.csv(df_res, paste(path_out,'all_final_fits.csv', sep=""), row.names = TRUE)
write.csv(df_paths, paste(path_out,'all_model_paths.csv', sep=""), row.names = TRUE)
write.csv(df_nCPBES, paste(path_out,'all_nCPBES.csv', sep=""), row.names = TRUE)
#write.csv(list_badoutputs, paste(path_out,'list_badoutputs.csv', sep=""))
ts
uuid_filtering
library(cstmr)
library(stringr)
library(lubridate)
library(scales)
# Define paths
root_directory = "C:/Users/20190285/Documents/GitHub/fiftyshadesofgrey"
path_out = paste(root_directory, "/data/out/", sep="")
path_in = paste(root_directory, "/data/in/", sep="")
# Set the working directory. Change this to the location of the example on the computer. Note that "/" is always used in R, also in Windows
setwd(paste(root_directory, "/src", sep=""))
# Source the scripts with functions in the "src" folder. Just a neat way of arranging helping functions in R
source("allmodels.R")
source("utils.R")
# Get all input files names
setwd(path_out)
list_file_names <- list.files(pattern = "*_fit.rda")
## ------------------------------------------------- Model selection post-processing -------------------------------------------------
# Saving dataframe initialization
R_coefs = c('Ria', 'Rie', 'Rea', 'Rih', 'Rim', 'Ris')
# Saving dataframe initialization
col_names <- c("uuid", "model_name", "HTC", "nCPBES", "iteration", "significance_prop", "residual_std", "residual_mean",
"Ti0" , "Tm0" , "Te0" , "Th0" , "Ts0" ,
"Ci" , "Cm" , "Ce" , "Ch" , "Cs" , "Rie", "Rea", "Ria", "Rim", "Rih", "Ris", "Rh" ,
"Aw" , "Ae" ,
"p11", "p22", "p33", "p44", "p55", "e11",
"Ti0_p" , "Tm0_p" , "Te0_p" , "Th0_p" , "Ts0_p" , "Ci_p" , "Cm_p" , "Ce_p" , "Ch_p" , "Cs_p" ,
"Rie_p", "Rea_p", "Ria_p", "Rim_p", "Rih_p", "Ris_p", "Rh_p" ,
"Aw_p" , "Ae_p" ,
"p11_p", "p22_p", "p33_p", "p44_p", "p55_p", "e11_p")
col_names2 <- c("uuid", "ite1", "ite2", "ite3", "ite4", "ite5", "ite6")
# Initialize dataframes
# Results
df_res <- data.frame(matrix(ncol = length(col_names), nrow = 0))
colnames(df_res) <- col_names
# Best path
df_paths <- data.frame(matrix(ncol = length(col_names2), nrow = 0))
colnames(df_paths) <- col_names2
# Best nCPBES
df_nCPBES <- data.frame(matrix(ncol = length(col_names2), nrow = 0))
colnames(df_nCPBES) <- col_names2
# Estimated coefficient p-values, for significance evaluation
coef_pvals <- c("Ti0_p" , "Tm0_p" , "Te0_p" , "Th0_p" , "Ts0_p" ,
"Ci_p" , "Cm_p" , "Ce_p" , "Ch_p" , "Cs_p" ,
"Rie_p", "Rea_p", "Ria_p", "Rim_p", "Rih_p", "Ris_p", "Rh_p" ,
"Aw_p" , "Ae_p" ,
"p11_p", "p22_p", "p33_p", "p44_p", "p55_p", "e11_p")
### Looping over building model files
counts <- 0
list_badoutputs <- c()
for (file in list_file_names){
# --- PREPROCESSING ---
# Read the csv file
load(file)
# Get blg uuid from file name
split_file_name <- str_split_fixed(file, "_", 3)
uuid_filtering <- sapply(split_file_name, tail, 1)[[1]]
# Testing if the result evaluated is correct
if (length(best_fit) == 1) {
list_badoutputs <- c(list_badoutputs, file)
next
} else {
counts <- counts + 1
}
# Extracting model result
val <- summary(best_fit)
# Identifying R coefs from results
coefs <- val$coefficients[1:(length(val$coefficients)/4),1]
coefs_p <- val$coefficients[1:(length(val$coefficients)/4),4]
R_coefs_considered <- Reduce(intersect,list(R_coefs,names(coefs)))
# Calculating HTC in function of available R coefficients
if ("Ria" %in% R_coefs_considered & "Rie" %in% R_coefs_considered & "Rea" %in% R_coefs_considered){
HTC <- 1/(coefs[['Rie']] + coefs[['Rea']]) + 1/coefs[['Ria']] # [kW/C]
} else if ("Rie" %in% R_coefs_considered & "Rea" %in% R_coefs_considered) {
HTC <- 1/(coefs[['Rie']] + coefs[['Rea']]) # [kW/C]
} else {
HTC <- 1/coefs[['Ria']] # [kW/C]
}
# Saving HTC value
df_res[[counts, 3]] <- HTC
# Save coefficients and their respective p-values
for (i in 1:length(names(coefs))){
df_res[[counts,  names(coefs)[i]]] <- coefs[[names(coefs)[i]]]        # parameter estimates
df_res[[counts,  paste(names(coefs_p)[i], "_p", sep="")]] <- coefs_p[[names(coefs_p)[i]]]  # parameter p-values
}
# Save uuid, model name
df_res[[counts, 1]] <- uuid_filtering
df_res[[counts, 2]] <- best_fit$model_name
# Save model selection path
df_paths[[counts, 1]] <- uuid_filtering
for (i in 1:length(best_fit$best_path)){
df_paths[[counts, i+1]] <- best_fit$best_path[i]
}
# Save model nCPBES
df_nCPBES[[counts, 1]] <- uuid_filtering
for (i in 1:length(best_fit$nCPBES)){
df_nCPBES[[counts, i+1]] <- best_fit$nCPBES[i]
}
### Save normalized Cumulated Periodogram Boundary Excess Sum
df_res[[counts, 4]] <- tail(best_fit$nCPBES, n=1)
# Saving Model Iteration
df_res[[counts, 5]] <- length(best_fit$best_path)
# Significance of estimated parameter - proportion: significance_prop
signifiance <- c()
for (c in coef_pvals){
signifiance <- c(signifiance, df_res[[counts, c]] < 0.05)
}
significance_prop <- sum(signifiance[!is.na(signifiance)]*1)/length(signifiance[!is.na(signifiance)])*100
df_res[[counts, 6]] <- significance_prop
## Residuals standard deviation & Mean values
# Loading data associated with results model
df <- read.csv(paste(path_in,"blg_",uuid_filtering,".csv",sep=""),sep=";",header=TRUE)
# Convert to datetime
df$timedate <- ymd_hms(df$t)
df$t <- seq(0, length(df$t)-1, by=1) / 4  # dt = 15 minutes
# Renaming Th to Thm
df$Thm <- df$Th
# Define input X
X <- df[c("t", "Ps", "Ta", "Thm", "yTi", "timedate")]
X = X[complete.cases(X), ]
# Calculate the one-step predictions of the state (i.e. the residuals)
tmp <- predict(best_fit)[[1]]
# Calculate the residuals and put them with the data in a data.frame X
X$residuals <- X$yTi - tmp$output$pred$yTi
# Saving Residual standard deviation & Mean
df_res[[counts, 7]] <- sd(X$residuals)
df_res[[counts, 8]] <- mean(X$residuals)
}
# Save dataframe as csv file/ spark table
write.csv(df_res, paste(path_out,'all_final_fits.csv', sep=""), row.names = TRUE)
write.csv(df_paths, paste(path_out,'all_model_paths.csv', sep=""), row.names = TRUE)
write.csv(df_nCPBES, paste(path_out,'all_nCPBES.csv', sep=""), row.names = TRUE)
#write.csv(list_badoutputs, paste(path_out,'list_badoutputs.csv', sep=""))
